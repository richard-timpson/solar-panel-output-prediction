{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0, '../DataCleaning')\n",
    "\n",
    "import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<module 'train_test_split' from '../DataCleaning/train_test_split.py'>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../../data/production_data/site_metadata.json', 'r') as file:\n",
    "    s = file.read()\n",
    "    site_md = json.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1232644 116439\n"
    }
   ],
   "source": [
    "from os.path import exists\n",
    "\n",
    "splits = {}\n",
    "\n",
    "#Warning, this takes a while because the join operation is implemented inefficently (like n^2 in the worst case.)\n",
    "for site in site_md:\n",
    "    site_id = site['id']\n",
    "    irradiance_site_id = site['irradiance_site_id']\n",
    "    tz_str = site['location']['timeZone']\n",
    "    \n",
    "    path_production = f\"{DATA_DIR}/production_data/raw/{site_id}/combination_data/production_weather_combination.csv\"\n",
    "    path_irradiance = f\"{DATA_DIR}/irradiance_data/raw/{irradiance_site_id}/irradiance_data.csv\"\n",
    "    \n",
    "    if not exists(path_irradiance):\n",
    "        print(site_id,irradiance_site_id)\n",
    "        continue\n",
    "    \n",
    "    X,Y,title_row = train_test_split.get_irradiance_WPI_data(path_production,path_irradiance, 4,3,tz_str)\n",
    "    splits[site_id] = (X,Y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['day',\n 'hour',\n 'precipIntensity',\n 'precipProbability',\n 'precipAccumulation',\n 'precipType_',\n 'precipType_rain',\n 'precipType_snow',\n 'precipType_sleet',\n 'temperature',\n 'apparentTemperature',\n 'dewPoint',\n 'humidity',\n 'pressure',\n 'windSpeed',\n 'windBearing',\n 'windGust',\n 'cloudCover',\n 'uvIndex',\n 'visibility',\n 'ozone',\n 'GHI',\n 'DHI',\n 'DNI']"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "title_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def mean_absoluate_percentage_error(y_true,y_pred):\n",
    "    \n",
    "    return np.mean( np.abs((y_true-y_pred) / y_true) ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def run_regression(site_id, data):\n",
    "    ([X_train,X_test],[Y_train,Y_test]) = data\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(Y_test,Y_pred))\n",
    "    rmse_norm = rmse / np.max(Y_test)\n",
    "\n",
    "    return model, rmse_norm \n",
    "\n",
    "def save_model(site_id, model):\n",
    "    d = f'../../models/production/{site_id}'\n",
    "\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)\n",
    "\n",
    "    filename = f'{d}/v1.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RMSE Norm for site 103941: 0.08617516488984574\nsaving model\nRMSE Norm for site 787197: 0.13784302620638708\nsaving model\nRMSE Norm for site 238320: 0.11149979860468122\nsaving model\nRMSE Norm for site 349060: 0.0774483298763127\nsaving model\nRMSE Norm for site 477834: 0.1460642753996398\nsaving model\nRMSE Norm for site 641826: 0.1333587028370901\nsaving model\nRMSE Norm for site 896164: 0.13672384235366947\nsaving model\nRMSE Norm for site 717193: 0.14732528873132125\nsaving model\nRMSE Norm for site 627759: 0.09262699169771013\nsaving model\nRMSE Norm for site 569932: 0.12163420567135913\nsaving model\nRMSE Norm for site 466851: 0.1154115891681261\nsaving model\nRMSE Norm for site 256177: 0.1221341033221149\nsaving model\nRMSE Norm for site 505347: 0.1173749200656108\nsaving model\n"
    }
   ],
   "source": [
    "for site, split in splits.items():\n",
    "    model, rmse_norm = run_regression(site, split)\n",
    "    print(f'RMSE Norm for site {site}: {rmse_norm}')\n",
    "    print('saving model')\n",
    "    save_model(site, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}